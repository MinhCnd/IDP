{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c310d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "# Will load LayoutLMv3ForTokenClassification\n",
    "MODEL_PATH = \"C:/Projects/IDP/watercare/model_output/23_11_03_03/checkpoint-150\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03696d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "# we'll use the Auto API here - it will load LayoutLMv3Processor behind the scenes,\n",
    "# based on the checkpoint we provide from the hub\n",
    "processor = AutoProcessor.from_pretrained(MODEL_PATH, apply_ocr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe97c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pdf to images\n",
    "from pdf2image import convert_from_path\n",
    "from pathlib import Path\n",
    "\n",
    "# Open a pdf file\n",
    "images = convert_from_path(Path(\"C:/Projects/IDP/watercare/dataset/pdfs/23_10_25.pdf\"), fmt=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a34d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from idp.annotations.bbox_utils import normalize_box\n",
    "\n",
    "def extract_text_from_image(image):\n",
    "    img_width, img_height = image.size\n",
    "    tesseract_output = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
    "    boxes = []\n",
    "    texts = []\n",
    "    for i, level_idx in enumerate(tesseract_output[\"level\"]):\n",
    "        if level_idx == 5:\n",
    "            bbox = [tesseract_output[\"left\"][i],\n",
    "                    tesseract_output[\"top\"][i],\n",
    "                    tesseract_output[\"left\"][i]+tesseract_output[\"width\"][i],\n",
    "                    tesseract_output[\"top\"][i]+tesseract_output[\"height\"][i]\n",
    "            ]\n",
    "            if not tesseract_output[\"text\"][i].strip():\n",
    "                continue\n",
    "            bbox = normalize_box(bbox, img_width, img_height)\n",
    "            texts.append(tesseract_output[\"text\"][i])\n",
    "            boxes.append(bbox)\n",
    "\n",
    "    return (texts, boxes)\n",
    "\n",
    "pages = len(images)\n",
    "text_box_pairs = [extract_text_from_image(image) for image in images]\n",
    "texts = [pair[0] for pair in text_box_pairs]\n",
    "boxes = [pair[1] for pair in text_box_pairs]\n",
    "page_indexes = [[index] * len(text_arr) for index, text_arr in enumerate(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f40cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_box_a_within_box_b(box_a, box_b):\n",
    "    left_a, top_a, right_a, bottom_a = box_a\n",
    "    left_b, top_b, right_b, bottom_b = box_b\n",
    "    \n",
    "    # Check if Box B contains box A\n",
    "    return left_b<=left_a and top_b<=top_a and right_b>=right_a and bottom_b>=bottom_a\n",
    "    \n",
    "# Assume all pages have the same size\n",
    "img_width, img_height = images[0].size\n",
    "\n",
    "# HACK remove texts & boxes outside of Labelling area\n",
    "def text_box_relevant(text_box_page):\n",
    "    text, box, page = text_box_page\n",
    "    \n",
    "    if page == 0:\n",
    "        outer_box = normalize_box((1298,828,1536,1550), img_width, img_height)\n",
    "        return is_box_a_within_box_b(box, outer_box)\n",
    "    elif page == 1:\n",
    "        outer_box = normalize_box((139,119,827,1173), img_width, img_height)\n",
    "        return is_box_a_within_box_b(box, outer_box)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "out_texts = []\n",
    "out_boxes = []\n",
    "\n",
    "for page in range(pages):\n",
    "    filtered_list = list(filter(text_box_relevant, list(zip(texts[page], boxes[page], page_indexes[page]))))\n",
    "    results = [[text for text, box, page in filtered_list],[box for text, box, page in filtered_list]]\n",
    "    temp_texts, temp_boxes = results\n",
    "    out_texts.append(temp_texts)\n",
    "    out_boxes.append(temp_boxes)\n",
    "# texts, boxes = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1028301",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = processor(images=images, text=out_texts, boxes=out_boxes, truncation=True, padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af218c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0, 10574, 23124,  1254, 24559,  1103,  7545,   731,  3201,  1132,\n",
      "            4,   612,   449,   574,    68,   134,     4, 39101,    73,   330,\n",
      "          574,    68,  4981,     4,  6405, 41768, 24159,   820,     4,  5067,\n",
      "          449,   574,    68,   246,     4, 33981,    73,   330,   574,    68,\n",
      "         5220,     4,  1225,    68, 22619,     4,  2546, 24559,  1254, 35616,\n",
      "          117,     4,  1577,  1646,   250,  5606,   541,  2517,   111, 24559,\n",
      "          675,  2357,   360,   152,  2600,   564,    12, 19144,    12,  1922,\n",
      "          262,  4156,  5441, 16633,  1426,  2600,   820,    12, 37729,    12,\n",
      "         1922,   262,   541, 30144, 24559,  1132,     4,   612,   330,   574,\n",
      "         3201,  1132,     4,   612,   330,   574, 41768, 24159,   787,  5479,\n",
      "            4,  1096,   207,   820,     4,  4718,   330,   574,     2,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1])\n"
     ]
    }
   ],
   "source": [
    "# HACK - Trim tokens to match 512 \n",
    "# encoding['input_ids'] = encoding['input_ids'][:,:512]\n",
    "# encoding['attention_mask'] = encoding['attention_mask'][:,:512]\n",
    "# encoding['bbox'] = encoding['bbox'][:,:512]\n",
    "\n",
    "print(encoding['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0512d4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhc\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\idp-1bLbv9p1-py3.10\\lib\\site-packages\\transformers\\modeling_utils.py:905: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "  outputs = model(**encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d71ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = outputs.logits.argmax(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31c5573f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-OTHER',\n",
       " 1: 'B-BALANCE_STILL_OWING',\n",
       " 2: 'B-WATER_CONSUMPTION',\n",
       " 3: 'B-WASTEWATER_CONSUMPTION',\n",
       " 4: 'B-WASTEWATER_FIXED',\n",
       " 5: 'B-BALANCE_CURRENT_CHARGES',\n",
       " 6: 'B-TOTAL_DUE',\n",
       " 7: 'B-WATER_CONSUMPTION_DETAILS',\n",
       " 8: 'B-WASTEWATER_CONSUMPTION_DETAILS',\n",
       " 9: 'B-WASTEWATER_FIXED_DETAILS',\n",
       " 10: 'B-THIS_READING',\n",
       " 11: 'B-LAST_READING'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da5e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idp.annotations.bbox_utils import unnormalize_box, merge_box_extremes\n",
    "from idp.annotations.annotation_utils import Classes, CLASS_TO_LABEL_MAP\n",
    "\n",
    "\n",
    "token_boxes = encoding.bbox.tolist()\n",
    "pages_input_ids = encoding['input_ids'].tolist()\n",
    "PAD_ID = 1\n",
    "# First token is a special token, ignore\n",
    "pad_indexes = [page_input_ids.index(PAD_ID) for page_input_ids in encoding['input_ids'].tolist()]\n",
    "true_predictions = [[model.config.id2label[pred] for pred in page_preds[1:pad_indexes[page_index]]] for page_index, page_preds in enumerate(predictions)]\n",
    "true_boxes = [[unnormalize_box(box, img_width, img_height) for box in page_token_boxes[1:pad_indexes[page_index]]] for page_index,page_token_boxes in enumerate(token_boxes)]\n",
    "true_texts = [[processor.tokenizer.decode([value]) for index, value in enumerate(page_input_ids[1:pad_indexes[page_index]])] for page_index,page_input_ids in enumerate(pages_input_ids)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f49ca77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = [{value: {'text':'','box':[]} for key,value in CLASS_TO_LABEL_MAP.items() if key != Classes.OTHER} for page in range(pages)]\n",
    "\n",
    "for page_indx in range(pages):\n",
    "    for key,value in CLASS_TO_LABEL_MAP.items():\n",
    "        if key == Classes.OTHER:\n",
    "            continue\n",
    "        output[page_indx][value]['text'] = ''.join([ text for text, prediction, box in zip(true_texts[page_indx], true_predictions[page_indx], true_boxes[page_indx]) if (prediction == value and box != [0,0,0,0])])\n",
    "        output[page_indx][value]['box'] = merge_box_extremes([box for text, prediction, box in zip(true_texts[page_indx], true_predictions[page_indx], true_boxes[page_indx]) if (prediction == value and box != [0,0,0,0])])\n",
    "\n",
    "# #trim empty outputs\n",
    "item_not_empty = lambda item : len(item[1]['text']) != 0\n",
    "filtered_output = [dict(filter(item_not_empty, page_output.items())) for page_output in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd1e0ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'B-BALANCE_STILL_OWING': {'text': ' $ 137.14 cr',\n",
       "   'box': [1385, 928, 1509, 949]},\n",
       "  'B-WATER_CONSUMPTION': {'text': ' $ 57.94', 'box': [1398, 1167, 1477, 1188]},\n",
       "  'B-WASTEWATER_CONSUMPTION': {'text': ' $79.11',\n",
       "   'box': [1398, 1195, 1474, 1216]},\n",
       "  'B-WASTEWATER_FIXED': {'text': ' $ 0.00', 'box': [1411, 1220, 1477, 1244]},\n",
       "  'B-BALANCE_CURRENT_CHARGES': {'text': ' $ 137.05',\n",
       "   'box': [1385, 1249, 1477, 1270]},\n",
       "  'B-TOTAL_DUE': {'text': ' $ 0.09 cr', 'box': [1411, 1457, 1509, 1478]}},\n",
       " {'B-WATER_CONSUMPTION_DETAILS': {'text': ' Water 29.00 kL $1.998/kL $ 57.94',\n",
       "   'box': [175, 254, 778, 285]},\n",
       "  'B-WASTEWATER_CONSUMPTION_DETAILS': {'text': ' Wastewater 22.76 kL $3.476/kL $79.11',\n",
       "   'box': [178, 278, 775, 311]},\n",
       "  'B-THIS_READING': {'text': ' This reading 25-Oct-23 759 Estimate',\n",
       "   'box': [178, 477, 798, 505]},\n",
       "  'B-LAST_READING': {'text': ' Last reading 22-Sep-23 730 Actual',\n",
       "   'box': [180, 505, 798, 526]}}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bbdbeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "# font = ImageFont.load_default()\n",
    "font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "\n",
    "def iob_to_label(label):\n",
    "    label = label[2:]\n",
    "    if not label:\n",
    "      return 'other'\n",
    "    return label\n",
    "\n",
    "label2color = {'other':'pink','balance_still_owing':'red', 'water_consumption':'purple', 'wastewater_consumption':'green', 'wastewater_fixed':'orange', 'balance_current_charges':'violet',\n",
    "              \"total_due\": \"black\",'water_consumption_details':'red','wastewater_consumption_details':'purple','wastewater_fixed_details':'green','this_reading':'grey','last_reading':'black'}\n",
    "\n",
    "for indx, page_output in enumerate(filtered_output):\n",
    "    draw = ImageDraw.Draw(images[indx])\n",
    "    for item in page_output.items():\n",
    "        predicted_label = iob_to_label(item[0]).lower()\n",
    "        box = item[1]['box']\n",
    "        draw.rectangle(box, outline=label2color[predicted_label])\n",
    "#         draw.text((box[0] - 100, box[1]), text=f\"{predicted_label}\", fill=label2color[predicted_label], font=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956fa521",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919370ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
